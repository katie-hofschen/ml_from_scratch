{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "from metrics import accuracy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F08E21\">Support Vector Machine (SVM)</span>\n",
    "\n",
    "Is a versatile and powerful ML model and can perform both linear and non-linear classification, regression or outlier detection.\\\n",
    "They can be particularly well-suited to classification for complex but small to medium sized datasets.\\\n",
    "SVM is sensitive to feature scales -> Scaling can be of benefit.\n",
    "\n",
    "### <span style=\"color:#217AB8\">Linear Classification with SVM</span>\n",
    "Set the boundary between classes so as to keep the largest margin between them, or placing the widest possible street between the classes. -> large margin classification.\\\n",
    "The decision boundary is determined/supported by the instances located on the edge of the street (named the support vectors). If you added more data that is beyond the street it would change nothing about the decision boundary.\n",
    "\n",
    "\n",
    "**&emsp;Soft vs Hard Margin Classification**\\\n",
    "&emsp; Hard margin: If all instances must be off the street and on the right side.\\\n",
    "&emsp; Downsides: Only works with linearly seperable data and is very sensitive to outliers. \n",
    "\n",
    "&emsp; Soft-margin: Find a balance between keeping the street as wide as possible and limit the margin violations.\\\n",
    "&emsp; A slightly more flexible model that may generalize better.\n",
    "\n",
    "&emsp; By controlling the width of the street eg. c variable the number of margin violations can be increased or decreased. (eg. scikit-learn high c lower margin violation)\n",
    "\n",
    "### <span style=\"color:#217AB8\">Non-Linear Classification with SVM</span>\n",
    "When the instances can not be separated by a linear decision boundary SVM makes use of non-linear methods.\n",
    "\n",
    "**&emsp;Polynomial Kernel**\\\n",
    "&emsp;Using the technique called the kernel trick it possible to get the same results as adding many polynomial features to your dataset, without actually having to add them.\\\n",
    "&emsp;Setting the polynomial to high can lead to overfitting, while setting it too low can lead to underfitting (eg. attempting linear boundaries with non-linear classes)\n",
    "\n",
    "**&emsp;Similarity Features**\\\n",
    "&emsp;Add features computed using a similarity function that measures how similar an instance is to a landmark.\\\n",
    "&emsp;An example of such a similarity function could be the Gaussian Radial Bias Function (RBF) which is a bell shaped function where 0 means the instance is far away from the landmark and 1 means it is right on top.\\\n",
    "&emsp;Applying this function and using it as the features to describe the data set makes the instances linearly separable. (selecting the landmarks close to each instance makes it more likely to become linearly separable.\\\n",
    "&emsp;However this explodes the dataset to have as many features as samples)\\\n",
    "&emsp;Again the Kernel trick can help you achieve the same complexity without adding so many new features.\n",
    "\n",
    "### <span style=\"color:#217AB8\">Regression with SVM</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
