{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "from metrics import accuracy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA: Principle Component Analysis \n",
    "\n",
    "### A bit of Background: Curse of Dimensionality\n",
    "Many datasets have thousands or even millions of features per training instance - Using all of them will likely slow down your training.     \n",
    "Consider that:     \n",
    "Some of the features may not even add much information and could be discarded or ignored.     \n",
    "Other features may be so highly correlated that you might be able to merge them into one and lose little information.     \n",
    "   \n",
    "Furthermore, most people can readily understand 3 dimensions but begin to struggle with 4 dimensions, let alone thousands.    \n",
    "Other particularities of high dimensional data:\n",
    "* In a unit square (1x1) points are unlikely to be extreme along any dimension whereas in a high dimensional space (eg. 10.000 dims) most points lay along the border of their spaces hypercube.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
